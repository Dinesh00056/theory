{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a931e6-3aa4-4625-ad0d-a6b281a1d4a2",
   "metadata": {},
   "source": [
    "# SVM(Support Vector Machine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6a7f8a-1124-4a5a-bdcd-1842f39ee868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM is supervised ml algorithm that is used for classification and regression task.\n",
    "# It is particularly affective in dealing with complex and high dimensional data set.\n",
    "# The fundamental principle of SVM is to find optimal hyperplane that maximise seperate different classes in the input space "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a799a3-a953-423f-b695-c8fb2d1171d9",
   "metadata": {},
   "source": [
    "# How SVM works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53508d90-11f8-429a-bb52-ce51ce2b04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) We will prepare our dataset.\n",
    "# 2) SVM require labeled training data consisting input feature and corresponding class label.\n",
    "# 3) Each data point is representing as a feature vector where each feature describe a particular characteristics of the data point. \n",
    "# 4) The datapoint should be preprocessed scaled to ensure the feature on similar scale typically betweeen 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88532a85-54c3-470a-a499-883ba048041b",
   "metadata": {},
   "source": [
    "# HyperPlane and Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd50e0f-0734-44aa-b8e5-1543c0fd3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM aims to find a hyperplane that best separates the different classes in the feature space.\n",
    "# In a binary classifcication problem the hyperplane is a line in a 2D space or in higher dimensional space.\n",
    "# SVM seeks to maximize the margin which is the distance between the hyperplane and the nearest datapoint  of each class.\n",
    "# The points of the margin are known as support vector as they play a crucial role in defining the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25632280-1ba9-4db6-baca-5a4818c0c6a5",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc5f11d-8c46-495c-90fc-c9c52aacfdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The linear SVM find a linear hyperplane that separate the classes the goal is to find the hyperplane that maximize the margin while minimizing \n",
    "# the misclassification of training example.Mathematical this can be formulated as an optimised problem with the objective off minimizing the weights \n",
    "# of the hyperplane subject to the constrait that all training example lies on the correct side of the hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6ec93-8776-4d44-a27a-5d62fa5ad294",
   "metadata": {},
   "source": [
    "# Non Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32a4b03a-a9b4-4986-8a0a-46222814da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In cases where data is not linearlly seprable SVM uses a technique called the kernel trick.The kernel trick maps the original input space into a higher \n",
    "# dimensional feature space where the data points can be linearly seprable.The choice of the kernel depends upon the characteristics of the data and the \n",
    "# problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116912a9-0019-4b4a-826e-ae704fe518a7",
   "metadata": {},
   "source": [
    "# Training of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "233d6c98-2fbd-4da6-8b4f-8d87175859a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM training involve find the optimal hyperplane or decision boundary that separates the classes the optimisation problem is typically solved using methods \n",
    "# such as Quadratic programming or sequencial minimal optimisation.The process involve solving for the weights of the hyperplane and the buyers term \n",
    "# # which define the decision boundary.The objective is to minimize the regularization term while ensuring that the training example are correctly classified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7588cfb-eed9-4bf6-96df-131858647900",
   "metadata": {},
   "source": [
    "# Predicition of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59c7e2-9ea9-461f-97a3-60a797d3c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the SVM model is trained it can be used to predict the class label of the new unseeen data points. This algorithm computes the distance from the test\n",
    "# points to the decision boundary The predict class label is determined based on width size of the decision boundary the points lies .The decision function\n",
    "# is also provide a confidience score and the probability estimate for the prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
